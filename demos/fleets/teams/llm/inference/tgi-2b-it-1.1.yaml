# # Copyright 2024 Google LLC
# #
# # Licensed under the Apache License, Version 2.0 (the "License");
# # you may not use this file except in compliance with the License.
# # You may obtain a copy of the License at
# #
# #      http://www.apache.org/licenses/LICENSE-2.0
# #
# # Unless required by applicable law or agreed to in writing, software
# # distributed under the License is distributed on an "AS IS" BASIS,
# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# # See the License for the specific language governing permissions and
# # limitations under the License.

# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: tgi-gemma-deployment
#   namespace: inference
#   labels: 
#     app: gemma-server
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: gemma-server
#   template:
#     metadata:
#       labels:
#         app: gemma-server
#         ai.gke.io/model: gemma-2b-1.1-it
#         ai.gke.io/inference-server: text-generation-inference
#         examples.ai.gke.io/source: user-guide
#     spec:
#       containers:
#       - name: busybox 
#         image: radial/busyboxplus:curl
#         command: ['sh', '-c', 'while true; do date; sleep 3; done'] 
#         resources:
#           requests:
#             cpu: "100m"
#             memory: "128Mi"
#       - name: llm-healthcheck 
#         image: us-docker.pkg.dev/fleet-dev-1/llm-healthcheck/llm-healthcheck-v0.0.12
#         resources:
#           requests:
#             cpu: "100m"
#             memory: "128Mi"
#         env:
#         - name: METRICS_ENDPOINT 
#           value: "http://localhost:8080/metrics" 
#         - name: METRICS_THRESHOLD
#           value: "15"
#         - name: METRIC_TO_CHECK 
#           value: "tgi_queue_size" 
#         - name: APP_PORT
#           value: "15021" 
#         ports:
#         - name: healthcheck
#           containerPort: 15021
#       - name: inference-server
#         image: us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-hf-tgi-serve:20240328_0936_RC01
#         # readinessProbe:
#         #   httpGet:
#         #     path: /health
#         #     port: 15021 # Port the llm-healthchecker is listening on
#         #   failureThreshold: 2
#         #   successThreshold: 2
#         #   initialDelaySeconds: 20 # Delay before first probe
#         #   periodSeconds: 5           
#         resources:
#           requests:
#             cpu: "2"
#             memory: "7Gi"
#             ephemeral-storage: "20Gi"
#             nvidia.com/gpu: 1
#           limits:
#             cpu: "2"
#             memory: "7Gi"
#             ephemeral-storage: "20Gi"
#             nvidia.com/gpu: 1
#         args:
#         - --model-id=$(MODEL_ID)
#         - --num-shard=1
#         env:
#         - name: MODEL_ID
#           value: google/gemma-1.1-2b-it
#         - name: PORT
#           value: "8080"
#         - name: HUGGING_FACE_HUB_TOKEN
#           valueFrom:
#             secretKeyRef:
#               name: hf-secret
#               key: hf_api_token
#         volumeMounts:
#         - mountPath: /dev/shm
#           name: dshm
#         ports:
#         - name: web
#           containerPort: 8080
#       volumes:
#       - name: dshm
#         emptyDir:
#           medium: Memory
#       nodeSelector:
#         cloud.google.com/gke-accelerator: nvidia-tesla-a100
